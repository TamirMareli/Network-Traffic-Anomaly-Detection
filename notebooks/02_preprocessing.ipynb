{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6902ddc",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 02_preprocessing.ipynb — NSL-KDD (Clean → Locked Schema CSVs)\n",
    "# ==============================================================================\n",
    "# GOAL\n",
    "# - Single source of truth for *data cleaning* and *label mapping*.\n",
    "# - Outputs: `data/processed/train_cleaned.csv` and `data/processed/test_cleaned.csv`\n",
    "# - Notebook 03 will **only** train models (no cleaning duplication).\n",
    "#\n",
    "# NOTES\n",
    "# - We rename `difficulty` → `level` (and keep it) so Notebook 03 can safely drop it.\n",
    "# - We do NOT fit/serialize sklearn preprocessors here (Notebook 03 owns that).\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Paths\n",
    "# ----------------------------------------------------------------------\n",
    "def get_project_root() -> Path:\n",
    "    cwd = Path.cwd().resolve()\n",
    "    return cwd.parent if cwd.name == \"notebooks\" else cwd\n",
    "\n",
    "PROJECT_ROOT = get_project_root()\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_path = RAW_DIR / \"KDDTrain+.txt\"\n",
    "test_path  = RAW_DIR / \"KDDTest+.txt\"\n",
    "\n",
    "print(f\"[✓] Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"[✓] RAW_DIR:      {RAW_DIR}\")\n",
    "print(f\"[✓] OUT_DIR:      {PROCESSED_DIR}\")\n",
    "\n",
    "if not train_path.exists() or not test_path.exists():\n",
    "    raise FileNotFoundError(\"Missing NSL-KDD raw files in data/raw (KDDTrain+.txt, KDDTest+.txt).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48249b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# NSL-KDD column names (official)\n",
    "# ----------------------------------------------------------------------\n",
    "COLUMNS = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'label', 'difficulty'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Load raw data\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"[1] Loading raw datasets...\")\n",
    "\n",
    "train_df = pd.read_csv(train_path, names=COLUMNS)\n",
    "test_df  = pd.read_csv(test_path,  names=COLUMNS)\n",
    "\n",
    "print(f\"[✓] Loaded train={train_df.shape}, test={test_df.shape}\")\n",
    "\n",
    "# Some versions of KDDTest+ come with 42 cols; in that case, 'difficulty' is NaN\n",
    "if 'difficulty' in test_df.columns and test_df['difficulty'].isna().all():\n",
    "    print(\"[i] Test difficulty column appears missing in file (all NaN). Keeping as NaN for consistency.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Basic cleaning (NO leakage)\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n[2] Basic cleaning...\")\n",
    "\n",
    "def basic_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # Standardize label text\n",
    "    out['label'] = out['label'].astype(str).str.lower().str.strip()\n",
    "\n",
    "    # Fix known NSL-KDD quirk: su_attempted sometimes has value 2, treat as 1 (binary)\n",
    "    if 'su_attempted' in out.columns:\n",
    "        out['su_attempted'] = pd.to_numeric(out['su_attempted'], errors='coerce').fillna(0)\n",
    "        out.loc[out['su_attempted'] > 0, 'su_attempted'] = 1\n",
    "\n",
    "    # Enforce numeric types where expected\n",
    "    # (Leave protocol_type/service/flag as categorical strings)\n",
    "    # Convert everything else except label/protocol_type/service/flag\n",
    "    cat_cols = {'protocol_type', 'service', 'flag', 'label'}\n",
    "    for c in out.columns:\n",
    "        if c not in cat_cols:\n",
    "            out[c] = pd.to_numeric(out[c], errors='coerce')\n",
    "\n",
    "    # Fill remaining NaNs in numeric with 0 (safe default for NSL-KDD counts/flags)\n",
    "    num_cols = out.columns.difference(list(cat_cols))\n",
    "    out[num_cols] = out[num_cols].fillna(0)\n",
    "\n",
    "    # Rename difficulty → level for consistency with Notebook 03 DROP_COLS\n",
    "    if 'difficulty' in out.columns:\n",
    "        out = out.rename(columns={'difficulty': 'level'})\n",
    "\n",
    "    return out\n",
    "\n",
    "train_df = basic_clean(train_df)\n",
    "test_df  = basic_clean(test_df)\n",
    "\n",
    "# Drop duplicates (train & test independently)\n",
    "before_tr = len(train_df)\n",
    "before_te = len(test_df)\n",
    "train_df = train_df.drop_duplicates()\n",
    "test_df  = test_df.drop_duplicates()\n",
    "print(f\"[✓] Dropped duplicates: train {before_tr-len(train_df)}, test {before_te-len(test_df)}\")\n",
    "\n",
    "# Quick missing-values check (should be 0 after fill)\n",
    "print(f\"[✓] Total NaNs: train={int(train_df.isna().sum().sum())}, test={int(test_df.isna().sum().sum())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Label mapping (4-class + binary)\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n[3] Mapping labels...\")\n",
    "\n",
    "attack_mapping = {\n",
    "    'normal': 'Normal',\n",
    "    # DoS\n",
    "    'back': 'DoS', 'land': 'DoS', 'neptune': 'DoS', 'pod': 'DoS', 'smurf': 'DoS', 'teardrop': 'DoS',\n",
    "    'mailbomb': 'DoS', 'apache2': 'DoS', 'processtable': 'DoS', 'udpstorm': 'DoS', 'worm': 'DoS',\n",
    "    # Probe\n",
    "    'satan': 'Probe', 'ipsweep': 'Probe', 'nmap': 'Probe', 'portsweep': 'Probe', 'mscan': 'Probe', 'saint': 'Probe',\n",
    "    # R2L\n",
    "    'guess_passwd': 'R2L', 'ftp_write': 'R2L', 'imap': 'R2L', 'phf': 'R2L', 'multihop': 'R2L',\n",
    "    'warezmaster': 'R2L', 'warezclient': 'R2L', 'spy': 'R2L', 'xlock': 'R2L', 'xsnoop': 'R2L',\n",
    "    'snmpguess': 'R2L', 'snmpgetattack': 'R2L', 'httptunnel': 'R2L', 'sendmail': 'R2L', 'named': 'R2L',\n",
    "    # U2R\n",
    "    'buffer_overflow': 'U2R', 'loadmodule': 'U2R', 'perl': 'U2R', 'rootkit': 'U2R', 'ps': 'U2R',\n",
    "    'sqlattack': 'U2R', 'xterm': 'U2R'\n",
    "}\n",
    "\n",
    "def map_attack_class(label_series: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        label_series.astype(str)\n",
    "        .str.lower().str.strip()\n",
    "        .map(attack_mapping)\n",
    "        .fillna('Normal')\n",
    "    )\n",
    "\n",
    "for df in (train_df, test_df):\n",
    "    df['attack_class'] = map_attack_class(df['label'])\n",
    "    df['binary_target'] = (df['attack_class'] != 'Normal').astype(int)\n",
    "\n",
    "print(\"[✓] Distributions (train):\")\n",
    "print(train_df['attack_class'].value_counts())\n",
    "print(\"\\n[✓] Binary distribution (train):\")\n",
    "print(train_df['binary_target'].value_counts())\n",
    "print(\"\\n[✓] Binary distribution (test):\")\n",
    "print(test_df['binary_target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5befebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Schema lock (feature columns only) + save cleaned CSVs\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n[4] Locking schema and saving cleaned CSVs...\")\n",
    "\n",
    "# Keep these columns in the cleaned output for Notebook 03\n",
    "# (Notebook 03 will drop label/attack_class/binary_target/level safely.)\n",
    "KEEP_COLS = list(train_df.columns)\n",
    "\n",
    "# Ensure both have the same columns in the same order\n",
    "all_cols = sorted(set(train_df.columns).union(set(test_df.columns)))\n",
    "train_out = train_df.reindex(columns=all_cols, fill_value=0)\n",
    "test_out  = test_df.reindex(columns=all_cols, fill_value=0)\n",
    "\n",
    "out_train_path = PROCESSED_DIR / \"train_cleaned.csv\"\n",
    "out_test_path  = PROCESSED_DIR / \"test_cleaned.csv\"\n",
    "\n",
    "train_out.to_csv(out_train_path, index=False)\n",
    "test_out.to_csv(out_test_path, index=False)\n",
    "\n",
    "print(f\"[✓] Saved: {out_train_path}  shape={train_out.shape}\")\n",
    "print(f\"[✓] Saved: {out_test_path}   shape={test_out.shape}\")\n",
    "\n",
    "# Minimal integrity checks\n",
    "assert set(train_out.columns) == set(test_out.columns)\n",
    "assert 'label' in train_out.columns and 'label' in test_out.columns\n",
    "print(\"[✓] Integrity checks passed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
