{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac25c85",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 1. Imports & Configuration\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c74b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Attempt to import XGBoost (Optional high-performance model)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    print(\"[!] XGBoost not installed. Using Random Forest only.\")\n",
    "    XGBClassifier = None\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ed479",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# --- Configuration ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead39a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    Robustly find project root whether notebook is run from /notebooks or repo root.\n",
    "    Looks for a folder reminding a repo structure: 'data' and 'src'.\n",
    "    \"\"\"\n",
    "    cwd = Path.cwd().resolve()\n",
    "\n",
    "    # candidate roots: cwd and cwd.parent (covers running from repo root or from notebooks/)\n",
    "    candidates = [cwd, cwd.parent]\n",
    "\n",
    "    for root in candidates:\n",
    "        if (root / \"data\").exists() and (root / \"src\").exists():\n",
    "            return root\n",
    "\n",
    "    # fallback: assume notebooks/ and go one up\n",
    "    return cwd.parent\n",
    "\n",
    "PROJECT_ROOT = get_project_root()\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"results\" / \"models\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"results\" / \"figures\"\n",
    "METRICS_DIR = PROJECT_ROOT / \"results\" / \"metrics\"\n",
    "\n",
    "\n",
    "# Create directories if they don't exist\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plotting Style (Academic Paper Standard)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "def save_plot(filename: str) -> None:\n",
    "    path = FIGURES_DIR / f\"{filename}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()  # ×—×©×•×‘ ×œ×”×¨×¦×•×ª ×—×•×–×¨×•×ª\n",
    "    print(f\"[+] Plot saved: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fcb6c",
   "metadata": {},
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. Load Preprocessed Data\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac54f91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loading preprocessed data artifacts...\n",
      "[+] Data loaded successfully.\n",
      "    X_train shape: (125973, 122)\n",
      "    Target Classes (Multi): ['DoS' 'Normal' 'Probe' 'R2L' 'U2R']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[1] Loading preprocessed data artifacts...\")\n",
    "\n",
    "try:\n",
    "    # Load Feature Matrices\n",
    "    X_train = np.load(PROCESSED_DIR / \"X_train.npy\")\n",
    "    X_test = np.load(PROCESSED_DIR / \"X_test.npy\")\n",
    "    \n",
    "    # Load Labels\n",
    "    y_train_binary = np.load(PROCESSED_DIR / \"y_train_binary.npy\")\n",
    "    y_test_binary = np.load(PROCESSED_DIR / \"y_test_binary.npy\")\n",
    "    y_train_multi = np.load(PROCESSED_DIR / \"y_train_multi.npy\")\n",
    "    y_test_multi = np.load(PROCESSED_DIR / \"y_test_multi.npy\")\n",
    "    \n",
    "    # Load Metadata (Feature names & Label Encoders for the Dashboard)\n",
    "    feat_path = PROCESSED_DIR / \"feature_names.csv\"\n",
    "    if feat_path.exists():\n",
    "        feature_names = pd.read_csv(feat_path)[\"feature\"].tolist()\n",
    "    else:\n",
    "        feature_names = [f\"feat_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "    with open(PROCESSED_DIR / \"label_encoder.pkl\", \"rb\") as f:\n",
    "        le = pickle.load(f)\n",
    "        \n",
    "    print(f\"[+] Data loaded successfully.\")\n",
    "    print(f\"    X_train shape: {X_train.shape}\")\n",
    "    print(f\"    Target Classes (Multi): {le.classes_}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Missing data files in {PROCESSED_DIR}. Run 02_preprocessing.ipynb first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e8177",
   "metadata": {},
   "source": [
    "\n",
    "# ==========================================\n",
    "# 3. Evaluation Helper Function\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0db68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name, is_binary=True):\n",
    "    \"\"\"\n",
    "    Evaluates a model and generates standard academic plots.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Evaluating: {model_name} ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if (is_binary and hasattr(model, \"predict_proba\")) else None\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    # 2. Metrics\n",
    "    if is_binary:\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "    else:\n",
    "        # Multi-class metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Weighted F1: {f1:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    # 3. Confusion Matrix Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    labels = [\"Normal\", \"Attack\"] if is_binary else le.classes_\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    save_plot(f\"cm_{model_name.replace(' ', '_').lower()}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. ROC Curve (Binary Only)\n",
    "    if is_binary and y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.3f}')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        save_plot(f\"roc_{model_name.replace(' ', '_').lower()}\")\n",
    "        plt.show()\n",
    "\n",
    "    return {\"Model\": model_name, \"F1\": f1, \"Time\": inference_time}\n",
    "\n",
    "# Store results\n",
    "results_log = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1690c",
   "metadata": {},
   "source": [
    "\n",
    "# ==========================================\n",
    "# 4. Training Binary Models (Detection)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522da527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Training Logistic Regression (Baseline)...\n",
      "\n",
      "--- Evaluating: Logistic Regression ---\n",
      "Accuracy:  0.4308\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\cm_logistic_regression.png\n",
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\roc_logistic_regression.png\n",
      "\n",
      "[3] Training Random Forest (Binary)...\n",
      "\n",
      "--- Evaluating: Random Forest Binary ---\n",
      "Accuracy:  0.4312\n",
      "Precision: 1.0000\n",
      "Recall:    0.0008\n",
      "F1 Score:  0.0016\n",
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\cm_random_forest_binary.png\n",
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\roc_random_forest_binary.png\n",
      "\n",
      "[4] Training XGBoost (Binary)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:199: UserWarning: [19:27:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating: XGBoost Binary ---\n",
      "Accuracy:  0.4308\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\cm_xgboost_binary.png\n",
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\roc_xgboost_binary.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Objective: Fast & Accurate detection (Is it an attack?)\n",
    "\n",
    "# --- Model A: Logistic Regression (Baseline) ---\n",
    "print(\"\\n[2] Training Logistic Regression (Baseline)...\")\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    solver=\"lbfgs\",\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "lr_model.fit(X_train, y_train_binary)\n",
    "results_log.append(evaluate_model(lr_model, X_test, y_test_binary, \"Logistic Regression\"))\n",
    "\n",
    "# --- Model B: Random Forest (The Workhorse) ---\n",
    "print(\"\\n[3] Training Random Forest (Binary)...\")\n",
    "rf_binary = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "rf_binary.fit(X_train, y_train_binary)\n",
    "results_log.append(evaluate_model(rf_binary, X_test, y_test_binary, \"Random Forest Binary\"))\n",
    "\n",
    "# --- Model C: XGBoost (If available) ---\n",
    "if XGBClassifier:\n",
    "    print(\"\\n[4] Training XGBoost (Binary)...\")\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=6,\n",
    "        use_label_encoder=False, eval_metric='logloss',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train_binary)\n",
    "    results_log.append(evaluate_model(xgb_model, X_test, y_test_binary, \"XGBoost Binary\"))\n",
    "else:\n",
    "    xgb_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6e2dc",
   "metadata": {},
   "source": [
    "\n",
    "# ==========================================\n",
    "# 5. Training Multi-class Model (Classification)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc5c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] Training Multi-class Classifier (For Dashboard Details)...\n",
      "\n",
      "--- Evaluating: Random Forest Multi-class ---\n",
      "Accuracy:  0.6496\n",
      "Weighted F1: 0.5943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\elair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\elair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DoS       1.00      0.57      0.73      7460\n",
      "      Normal       0.55      1.00      0.71      9711\n",
      "       Probe       0.99      0.29      0.45      2421\n",
      "         R2L       0.00      0.00      0.00      2885\n",
      "         U2R       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.65     22544\n",
      "   macro avg       0.51      0.37      0.38     22544\n",
      "weighted avg       0.67      0.65      0.59     22544\n",
      "\n",
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\cm_random_forest_multi-class.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'Random Forest Multi-class',\n",
       " 'F1': 0.5942570994341888,\n",
       " 'Time': 0.16780328750610352}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Objective: Provide description for the Dashboard (e.g., \"DoS Attack\")\n",
    "print(\"\\n[5] Training Multi-class Classifier (For Dashboard Details)...\")\n",
    "\n",
    "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_multi.fit(X_train, y_train_multi)\n",
    "\n",
    "# Evaluate Multi-class\n",
    "evaluate_model(rf_multi, X_test, y_test_multi, \"Random Forest Multi-class\", is_binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712fab0",
   "metadata": {},
   "source": [
    "\n",
    "# ==========================================\n",
    "# 6. Feature Importance (Interpretability)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cdb8298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] Feature Importance Analysis...\n",
      "[+] Plot saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\figures\\feature_importance.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n[6] Feature Importance Analysis...\")\n",
    "# Used for the report to explain WHAT the model is looking at\n",
    "importances = rf_binary.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(f\"Top {top_n} Features Driving Detection\")\n",
    "plt.bar(range(top_n), importances[indices[:top_n]], align=\"center\", color=\"#2c3e50\")\n",
    "plt.xticks(range(top_n), [feature_names[i] for i in indices[:top_n]], rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "save_plot(\"feature_importance\")\n",
    "plt.show()\n",
    "plt.savefig(\"feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7fa5d",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 7. Comparison & Selection\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e8d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison Table:\n",
      "                            F1      Time\n",
      "Model                                   \n",
      "Logistic Regression   0.000000  0.009052\n",
      "Random Forest Binary  0.001557  0.479590\n",
      "XGBoost Binary        0.000000  0.075537\n",
      "[+] Metrics table saved: C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\metrics\\model_comparison.csv\n",
      "\n",
      "[!] Selected Best Model for Production: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(results_log).set_index(\"Model\")\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "print(df_res)\n",
    "\n",
    "# save to disk for report\n",
    "metrics_path = METRICS_DIR / \"model_comparison.csv\"\n",
    "df_res.to_csv(metrics_path)\n",
    "print(f\"[+] Metrics table saved: {metrics_path}\")\n",
    "\n",
    "# Select best binary model for production (usually RF or XGB)\n",
    "best_model = xgb_model if xgb_model else rf_binary\n",
    "print(f\"\\n[!] Selected Best Model for Production: {type(best_model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee3f57",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 8. Save Models for Dashboard\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d281306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7] Saving Models for Real-time Dashboard...\n",
      "[+] Copied preprocessing artifacts to results/models/\n",
      "[+] Models saved to C:\\Users\\elair\\Desktop\\CS\\cyber_bootcamp\\Network-Traffic-Anomaly-Detection\\results\\models\n",
      "    - binary_model.pkl (Detection)\n",
      "    - multi_model.pkl  (Classification)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[7] Saving Models for Real-time Dashboard...\")\n",
    "\n",
    "# We need to save:\n",
    "# 1. The Best Binary Model (For \"Alert / No Alert\")\n",
    "# 2. The Multi-class Model (For \"What kind of attack is this?\")\n",
    "\n",
    "with open(MODELS_DIR / \"binary_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open(MODELS_DIR / \"multi_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_multi, f)\n",
    "\n",
    "# Copy preprocessing artifacts for dashboard convenience\n",
    "src_preprocessor = PROCESSED_DIR / \"preprocessor.pkl\"\n",
    "src_le = PROCESSED_DIR / \"label_encoder.pkl\"\n",
    "src_feat = PROCESSED_DIR / \"feature_names.csv\"\n",
    "\n",
    "if src_preprocessor.exists():\n",
    "    shutil.copy2(src_preprocessor, MODELS_DIR / \"preprocessor.pkl\")\n",
    "if src_le.exists():\n",
    "    shutil.copy2(src_le, MODELS_DIR / \"label_encoder.pkl\")\n",
    "if src_feat.exists():\n",
    "    shutil.copy2(src_feat, MODELS_DIR / \"feature_names.csv\")\n",
    "\n",
    "print(\"[+] Copied preprocessing artifacts to results/models/\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"[+] Models saved to {MODELS_DIR}\")\n",
    "print(\"    - binary_model.pkl (Detection)\")\n",
    "print(\"    - multi_model.pkl  (Classification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72735f01",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 9. SIMULATION: Real-Time Dashboard Logic\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefafdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8] Simulating Real-Time Dashboard Logic...\n",
      "This code snippet demonstrates how the dashboard will process a new packet.\n",
      "\n",
      "--- Incoming Packet (ID: 16661) ---\n",
      "True Label: Normal\n",
      "âœ… Traffic Normal (Confidence: 100.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[8] Simulating Real-Time Dashboard Logic...\")\n",
    "print(\"This code snippet demonstrates how the dashboard will process a new packet.\")\n",
    "\n",
    "# Simulate a single incoming packet (taken from Test set)\n",
    "random_idx = np.random.randint(0, len(X_test))\n",
    "sample_packet = X_test[random_idx].reshape(1, -1)\n",
    "true_label_code = y_test_multi[random_idx]\n",
    "true_label_str = le.inverse_transform([true_label_code])[0]\n",
    "\n",
    "print(f\"\\n--- Incoming Packet (ID: {random_idx}) ---\")\n",
    "print(f\"True Label: {true_label_str}\")\n",
    "\n",
    "# --- DASHBOARD LOGIC START ---\n",
    "# 1. Load Preprocessor & Models (Already done above, but conceptually:)\n",
    "# preprocessor = pickle.load(...)\n",
    "# binary_model = pickle.load(...)\n",
    "# multi_model = pickle.load(...)\n",
    "\n",
    "# 2. Detect Anomaly\n",
    "is_attack = best_model.predict(sample_packet)[0] # 0 or 1\n",
    "attack_prob = best_model.predict_proba(sample_packet)[0][1] # 0.0 to 1.0\n",
    "\n",
    "if is_attack == 1:\n",
    "    # 3. If Attack -> Classify Type\n",
    "    attack_code = rf_multi.predict(sample_packet)[0]\n",
    "    attack_type = le.inverse_transform([attack_code])[0]\n",
    "    \n",
    "    print(f\"ðŸš¨ ALERT TRIGGERED!\")\n",
    "    print(f\"   Confidence: {attack_prob:.2%}\")\n",
    "    print(f\"   Attack Type: {attack_type}\")\n",
    "    print(f\"   Action: Block IP & Log Incident.\")\n",
    "else:\n",
    "    print(f\"âœ… Traffic Normal (Confidence: {1-attack_prob:.2%})\")\n",
    "# --- DASHBOARD LOGIC END ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
